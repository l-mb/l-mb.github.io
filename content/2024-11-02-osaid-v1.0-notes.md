+++
title = "OSI's Open Source AI Definition v1.0"
date = "2024-11-02"

[taxonomies]
tags = ["Open Source", "Policy", "AI"]
+++

# Introduction

Artificial Intelligence (AI), most notably but not limited to its forms
of Generative AI and Large Language Models (LLMs) is, for better or
worse, has a growing impact in shaping critical societal outcomes; from
healthcare via finance to public safety in general (consider
self-driving cars). But also simply in our every day lives and jobs as
individuals.

Without openness and the transparency it enables, AI could perpetuate
unchecked biases that shape public policy, healthcare, and legal
outcomes. Without openness and the ability to modify them, we are robbed
of freedom and agency.

Such AI systems are (again, for better or worse) replacing or at the
very least augmenting more traditional Information Technology systems
that are controlled using established programming languages.

For those, we have now familiar concepts of Free, Libre, and Open Source
Software paradigms that strive to ensure our rights and abilities to not
just **Use**, but also to **Study**, **Modify**, and **Share** them.

For individuals and society at large not to be at the questionable mercy
of inscrutable blackboxes (often proprietarily controlled by for-profit
companies pursuing a shareholder primacy mentality), such rights are
fundamental. Not just that, Free, Libre, and Open Source Software
Systems nowadays underpin [inconceivable value for the global
economy][8].

Thus arises the desire and need to protect those freedoms to AI-driven
systems.

The [Open Source Initiative (OSI)](https://opensource.org/) has just
released the first version of their [Open Source AI Definition
(OSAID)][3] and its associated [Frequently Asked Questions (FAQ)][2],
providing further clarifications. (Please go read these two before
continuing on - I consider them the key source material and will not
fully summarize nor repeat them.)

The OSI declares themselves to the *"the authority* that defines Open
Source", and the steward of the [Open Source
Definition](https://opensource.org/definition/). It is fair to say that
they are one of the most influential organizations in this space, with
broad impact on the IT industry, communities, and even political
policies as a whole.

This means we must hold OSI's release of version one point zero, which
is no longer declared a draft asking for comments but for endorsement,
to a high standard and critically evaluate whether it manages to uphold
and protect the FLOSS values, and what might be needed to address any
gaps.

This is not the first writing, and I want to give explicit
acknowledgement to the sources cited at the end for influencing my
thinking; the tenor of the positions from the FSF or the Software
Freedom Conservancy's aspirational stance, but also other respected
individuals, clearly shows that advocates expect the OSI to do better.

# The Positive Intentions and Achievements

OSI has engaged with diverse stakeholders with not always perfectly
aligned interests and positions, and anyone who has ever worked on any
sort of large collaborative effort or standard recognizes the
impossibility to make everyone perfectly happy. Especially when global
stakeholders from all across the industry meet ethical and moral
concerns.

It is always easy to criticize someone else's work - after it has been
published. And we would not be having this discourse right now if they
hadn't. That is something that we should all recognize when we post our
commentary.

Providing an initial framework for "Open Source" AI and addressing a
previously largely undefined space is an important step that I do not
wish to discount. OSI is striving to provide a baseline to measure
against.

The key goal of OSAID is to beyond merely addressing the "traditional"
source code used to build, train, run, and operate AI Systems; it would
have been easy for OSI to limit themselves to this aspect which most
closely aligns with their original scope and experiences, and I consider
the recognition of the multi-dimensional nature of AI systems very
important.

## Software Source Code

Requiring the "complete" software source to be made available
under an OSI-approved license is the obvious application of FLOSS
principles to AI systems. This is fairly broadly phrased, including even
supporting libraries and the model architecture.

It would be nice if this included explicit requirements for the (kernel)
drivers as well, and there's always the question where "software" ends
for GPUs and other hardware components that implement quite complex
firmware. Or the layers through which a user interacts with the system
in the end (and which might further process the results).

I think this is indeed the minimal standard any "Open Source AI" system
must meet. Though if the scope was limited to this, I'd argue we have
not gone beyond anything we already understand well.

So how does OSI address the new aspects?

# Critique

## The Data

Positively, the OSAID *does* outline guidelines that clearly make
systems that comply with them more "open" than those that do not.

Describing the data used in fair detail, its provenance, the sourcing,
the processing, labelling, whether public or from *third parties
(including for fee)* <sub>(which is a more polite way of saying:
proprietary and non-free)</sub> is a significant step up from those
AI/ML systems where we have no idea.

However, here is also where OSAID falls crucially, critically short of
its stated goal: it does not even *recommend* that the training data
should be free/open by default, much less *require* it.

Unlike traditional software, AI/ML systems derive their **main** logic
and function from training on their *source* data. Not providing those
denies some of the core freedoms and rights.

Yes, traditional systems also use external assets (such as media) that
is not always governed by the same open/free rights as the source code,
but it was still possible to inspect how they processed them. (And it is
worth pointing out that some voices would not consider even such systems
"open" if they had critical non-open/non-free dependencies.) This data
is usually what they operate on or what configures the system, not the
system itself.

The [OSAID FAQ][2] elaborates that not all data *can* be free or open -
such as, say, confidential medical data, or situations where legislation
differ. And that is a clearly valid. [Even the Free Software Foundation
concedes this aspect,][6] arguing that nonfree AI/ML systems could still
be just.

Yet - to be able to assess whether a system was trained for a particular
situation, whether its training data contains any relevant biases that
might produce discriminatory results, that can *only* be reasonably done
if access to this data is open.

#### OSI-approved terms

Another shortcoming for OSAID to be truly meaningful is that, for even
the limited "data information" we get as well as the model parameters
and configuration settings, it specifies only that they "shall be made
available under *OSI-approved terms*".

Which, the FAQ elaborates somewhat unhelpfully, does **not** (yet?)
refer to any defined legal mechanisms, and can thus at best be seen as
an aspirational statement.

While a typical OSI-approved license that would govern source code does
not easily apply, since data is not software as such. Yet, the Linux
Foundation has developed [terms that might serve][9], and for the OSI to
suggest not anything here is disappointing.

For this to govern the key components beyond software source code
(which, I might remind the reader, is the entire *point*) it is far too
vague.

### A description of the data is not the data

**So:** for the recognized components that go beyond traditional
software systems, the OSAID does neither require their full openness
*nor* provide guidance on how to make the required information available
in a compliant manner.

## Limited Transparency and Ability to Audit

A key value Open Source Software adds to systems is the transparency to
inspect and audit their source code.

This is crucial for individuals and society to understand the systems
they're interacting with, uncover biases of all kinds -
non-representative data sets, discriminatory data, lack of coverage for
critical scenarios, or even intentional data sets that introduce
malicious exploits.

As discussed, this must necessarily imply access to all components,
notably the training data.

Running experiments on the resulting models remains necessary, but not
sufficient. It is already not feasible to thoroughly test traditional
software; it is similarly impossible to try and test a system whose
points of reference are unknown and opaque.

Not spotting and correcting these may result in reproducing gender- or
ethnic-bias in generated imagery. It could be used to manipulate
financial decisions. In scenarios such as healthcare, policing, or
autonomous vehicles, it might prove fatal.

## Modifying and Sharing

In my opinion, these two dimensions are slightly less of a priority in
the context of this critique (since they'd likely also be resolved by
addressing the core criticisms), but nonetheless necessary. Again, these
are greatly hindered by the weak requirements and rights provided.

Yes, models can be iteratively trained (depending on what "OSI-approved
terms" end up requiring), and that allows certain influences on their
behaviours. But that's not the same as the ability to rebuild or retrain
another, modified model.

Yes, this also needs to acknowledge that the training data can be huge;
not mere gigabytes, but exabytes. And that the hardware resources and
power requirements to train a model can be similarly vast. But we also
assume that available for FLOSS in general.

Still, for an "Open Source AI" definition to provide so little guidance
on how to actually modify and share those modifications fails to address
half of the Four Freedoms.

## Risk of Open-Washing - Undermining "Open Source"

Why then the insistence to call this by such a seemingly comprehensive
term as "Open Source AI"?

If the only part of the system that is truly "open" (or even free) in
the sense of Open Source Software, we should rather call this an "AI
System fully build with Open Source Software".

We do not call something "Open Source Software" if it just comes with a
description of what the source code looks like and where you can buy
access to it.

Unfortunately, the OSI has a history with such term dilution: "Open
Source Software" is a more industry-pleasing alternative to "Free
Software"; and calling less-protective licenses "more permissive" was a
stroke of marketing genius for capitalist-value-extraction.

This could lead to further undermining of the value of "Open Source" to
individuals and society, and in fact allow companies to use the
marketing branding of "Open Source AI" while, in fact, continuing
business as usual.

#### Superficial marketing term?

The additional demands placed on companies are not onerous: Free, Libre,
Open Source software is already the default for most AI/ML software
development and in many other areas of IT. Describing the data sources
is something some regulatory efforts (see next section) already request,
and in line with the general move towards strongly documented
supply-chains and bills of materials.

From their perspective, a superficial definition is preferable to one
with teeth, since it gives them an easy marketing win for another label
to stick on the box, with possibly additional benefits:

#### Potential implications for public policy and regulation

The [European Union's Artifical Intelligence Act][10] outlines certain
transparency requirements for AI systems. However, it also lowers
certain standards for "free and open license GPAI models".

It is not inconceivable that a company might claim compliance with the
OSAID to benefit from these reduced requirements, bamboozling policy
makers and public decision makers by using a term defined by a respected
industry organization.

This again demonstrates the need for the OSAID to be as true a
representation of Free, Libre, and Open values as possible.

# TL;DR 

The Open Source AI Definition v1.0 claims to set out to address the need
for a definition of "Open Source" in the context of AI/ML system; but it
falls critically short of ensuring the true openness of our
AI/ML-based information systems and thus our individual and societal
freedoms and safety.

As it stands, I can only conclude that "Open Source AI" is a somewhat
rushed marketing effort that does not actually deliver on what I would
expect or what I believe society needs, and risks further eroding our
rights.

Situations that have valid reasons for not making their sources publicly
accessible and open exist; data privacy around personal information and
medical data come to mind. For these systems to be just and aligned with
our human rights, they may not be able to be fully Open Source, and is a
tricky but quite feasible balance to maintain and regulate.

Such valid concerns should not allow other to take advantage of them for
their for-profit goals and marketing.

It dilutes the value of "Open Source" further, perhaps in the for-profit
corporate interests. We need a differentiated perspective that does just
to the full nuance and complexity of the new aspects of AI/ML-based
systems.

Given the speed at which AI/ML is adopted into critical infrastructure
and thus the urgent requirement to ensure its compatibility with our
values, *now* is the time to set our direction; we cannot afford to rush
this to serve industry stakeholders' marketing needs.

# Where to next

We need to create a nuanced and differentiated position beyond what
OSI's OSAID delivers today. My personal highest hope is for [the efforts
and aspirations of the Software Freedom Conservancy][4], who are well
positioned to act as true shepherds of our values in this space.

While it would be great if all of this could indeed be reduced to a
single term, recognizing the complexity of the real world might require
addressing Open Data, Open Source, and Open Weights separately, or
perhaps with multiple tiers per component. A *truly* open and just
system would also need to somehow address the resource requirements;
freedoms must be exercisable in reality.

This could come together under the broad umbrella of "Open Source AI",
but when used without qualification, this must at least default to real
openness for all covered components.

I hope that the currently on-going dialogue in the community, industry,
researchers, ethicists, policy makers, and media contributes to this
effort

Perhaps delivered via the *Open Source AI Definition, Version 2.0* - or
another organization's results, if OSI keeps their focus on industry
palatability.

# Sources

<!-- Don't come at me how ugly this is, you know how much willpower it
took not to disappear on a side quest of citation mgmt in Zola -->

{{ bib(num=1, desc="S. Vaughan-Nichols, “We have an official open-source AI definition now, but the fight is far from over”, ZDNET. Accessed: 2024-11-02", url="https://www.zdnet.com/article/we-have-an-official-open-source-ai-definition-now-but-the-fight-is-far-from-over/") }}
{{ bib(num=2, desc="Open Source Initiative, “OSAID FAQ.” Accessed: 2024-11-02", url="https://hackmd.io/@opensourceinitiative/osaid-faq#Why-will-parameters-be-available-under-OSI-approved-terms-but-the-code-will-be-under-OSI-approved-licenses-Are-you-going-to-allow-restrictions-on-the-terms-for-models") }}
{{ bib(num=3, desc="Open Source Initiative, “The Open Source AI Definition – 1.0,” Open Source Initiative. Accessed: 2024-11-02", url="https://opensource.org/ai/open-source-ai-definition") }}
{{ bib(num=4, desc="Software Freedom Conservancy, “SFC Announces Aspirational Statement on LLM-backed generative AI for Programming,” Software Freedom Conservancy. Accessed: 2024-11-02", url="https://sfconservancy.org/news/2024/oct/25/aspirational-on-llm-generative-ai-programming/") }}
{{ bib(num=5, desc="J. Brockmeier, “OSI readies controversial Open AI definition,” LWN.net. Accessed: 2024-11-02", url="https://lwn.net/Articles/995159/") }}
{{ bib(num=6, desc="Free Software Foundation, “FSF is working on freedom in machine learning applications.” Accessed: 2024-11-02", url="https://www.fsf.org/news/fsf-is-working-on-freedom-in-machine-learning-applications") }}
{{ bib(num=7, desc="tante, “Does Open Source AI really exist?,” Smashing Frames. Accessed: 2024-11-02", url="https://tante.cc/2024/10/16/does-open-source-ai-really-exist/") }}
{{ bib(num=8, desc="M. Hoffmann, F. Nagle, and Y. Zhou, “The Value of Open Source Software,” SSRN Journal, 2024", url="https://www.ssrn.com/abstract=4693148") }}
{{ bib(num=9, desc="The Linux Foundation, “Community Data License Agreement - Sharing, Version 1.0”, Accessed: 2024-11-02", url="https://cdla.dev/sharing-1-0/") }}
{{ bib(num=10, desc="European Parliament and Council, “Regulation (EU) 2024/1689 of the European Parliament and of the Council of 13 June 2024 laying down harmonised rules on artificial intelligence and amending Regulations”, Accessed: 2024-11-02", url="http://data.europa.eu/eli/reg/2024/1689/oj/eng") }}


